{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2020 Semester 1\n",
    "\n",
    "## Assignment 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):**    `Yanze Mao, Dong Cheng Ding\n",
    "\n",
    "**Student ID(s):**     `988142 952328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "review_text_test = pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_test.csv\")\n",
    "review_text_train = pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_train.csv\")\n",
    "review_text_test_meta = pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_meta_test.csv\")\n",
    "review_text_train_meta = pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_meta_train.csv\")\n",
    "review50=pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_train_doc2vec50.csv\",header=None)\n",
    "review100=pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_train_doc2vec100.csv\",header=None)\n",
    "review50_test=pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_test_doc2vec50.csv\",header=None)\n",
    "review100_test=pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_test_doc2vec100.csv\",header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB with countvectorizer\n",
    "\n",
    "NB_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer()),\n",
    "                (\"clf\", MultinomialNB())])\n",
    "NBparameters={\n",
    "     'tfidf__use_idf':(True,False),\n",
    "    'clf__alpha':[0,0.001,0.01,0.1,0.2],\n",
    "    'clf__fit_prior':[True,False]\n",
    "}\n",
    "NB_clf = GridSearchCV(NB_clf,NBparameters, cv = 5, n_jobs=-1)\n",
    "NB_clf=NB_clf.fit(review_text_train[\"review\"], review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__use_idf': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8413852073535699"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB with vect50,100,200\n",
    "\n",
    "NB_clf=Pipeline([\n",
    "                (\"clf\", GaussianNB())])\n",
    "NBparameters={\n",
    "    'clf__var_smoothing':[1e-9,1e-8]\n",
    "}\n",
    "NB_clf = GridSearchCV(NB_clf,NBparameters, cv = 5, n_jobs=-1)\n",
    "NB_clf=NB_clf.fit(review50, review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__var_smoothing': 1e-09}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6701938150206641"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84683882, 0.85518347, 0.84574279, 0.8376982 , 0.8492516 ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after adjustment of attributes, the best estimator with countervect:\n",
    "\n",
    "MLP_clf = Pipeline([('vect',CountVectorizer(stop_words=\"english\",decode_error='ignore')),\n",
    "                    (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                    ('clf',MLPClassifier(activation='relu', alpha=1e-05,\n",
    "       hidden_layer_sizes=(80,100,100), solver='lbfgs'))])\n",
    "\n",
    "\n",
    "scores2 = cross_validate(MLP_clf, review_text_train[\"review\"], review_text_train_meta[\"rating\"], cv = 5)\n",
    "scores2[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469429769356409"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75494212, 0.77075169, 0.76505166, 0.76679138, 0.76799715])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after adjustment of attributes, the best estimator with vect50,100,200:\n",
    "\n",
    "MLP_clf = Pipeline([\n",
    "                    ('clf',MLPClassifier(activation='relu', alpha=1e-05,\n",
    "       hidden_layer_sizes=(80,100,100), solver='lbfgs'))])\n",
    "\n",
    "\n",
    "scores2 = cross_validate(MLP_clf, review50, review_text_train_meta[\"rating\"], cv = 5)\n",
    "scores2[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76028495, 0.76237976, 0.7680798 , 0.76946374, 0.76853172])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after adjustment of attributes, the best estimator with vect50,100,200:\n",
    "\n",
    "MLP_clf = Pipeline([\n",
    "                    ('clf',MLPClassifier(solver='lbfgs'))])\n",
    "\n",
    "\n",
    "scores2 = cross_validate(MLP_clf, review100, review_text_train_meta[\"rating\"], cv = 5)\n",
    "scores2[\"test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with countervect\n",
    "SVM_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                (\"clf\", svm.SVC(kernel='linear', gamma=0.7, C=1.0))])\n",
    "\n",
    "SVMparameters={\n",
    "    \"clf__gamma\":[0.6,0.7,0.5,0.4],\n",
    "    \"clf__C\":[0.5,0.7,1.0,2.0]\n",
    "}\n",
    "SVMgs_clf = GridSearchCV(SVM_clf,SVMparameters, cv = 5, n_jobs=-1)\n",
    "SVMgs_clf=SVMgs_clf.fit(review_text_train[\"review\"], review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1.0, 'clf__gamma': 0.6}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMgs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMgs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with vect100\n",
    "SVM_clf=Pipeline([\n",
    "                (\"clf\", svm.SVC(kernel='linear', gamma=0.7, C=1.0))])\n",
    "\n",
    "SVMparameters={\n",
    "    \"clf__gamma\":[0.6,0.7,0.5,0.4],\n",
    "    \"clf__C\":[0.5,0.7,1.0,2.0]\n",
    "}\n",
    "SVMgs_clf = GridSearchCV(SVM_clf,SVMparameters, cv = 5, n_jobs=-1)\n",
    "SVMgs_clf=SVMgs_clf.fit(review100, review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8265640587145504"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMgs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with vect100\n",
    "SVM_clf=Pipeline([\n",
    "                (\"clf\", svm.SVC(kernel='linear', gamma=0.7, C=1.0))])\n",
    "\n",
    "SVMparameters={\n",
    "    \"clf__gamma\":[0.6,0.7,0.5,0.4],\n",
    "    \"clf__C\":[0.5,0.7,1.0,2.0]\n",
    "}\n",
    "SVMgs_clf = GridSearchCV(SVM_clf,SVMparameters, cv = 5, n_jobs=-1)\n",
    "SVMgs_clf=SVMgs_clf.fit(review50, review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8165170300698305"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMgs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.7, 'clf__gamma': 0.6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMgs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomforestclassifier with countervect\n",
    "RF_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "RFparameters={\n",
    "    \"tfidf__use_idf\":[True,False],\n",
    "    \"clf__n_estimators\":[100,300,500],\n",
    "    \"clf__criterion\":[\"gini\",\"entropy\"],\n",
    "    \"clf__max_depth\":[10,15,20,30],\n",
    "    \"clf__min_samples_split\":[2,4,6],\n",
    "}\n",
    "RF_clf = GridSearchCV(RF_clf,RFparameters, cv = 5, n_jobs=-1)\n",
    "RF_clf=RF_clf.fit(review_text_train[\"review\"], review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'gini',\n",
       " 'clf__max_depth': 30,\n",
       " 'clf__min_samples_split': 2,\n",
       " 'clf__n_estimators': 100,\n",
       " 'tfidf__use_idf': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6955251531993729"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7509975773122417"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomforestclassifier with countervect\n",
    "RF_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "RFparameters={\n",
    "    \"tfidf__use_idf\":[False],\n",
    "    \"clf__criterion\":[\"gini\",\"entropy\"],\n",
    "    \"clf__min_samples_split\":[2,4,6]\n",
    "}\n",
    "RF_clf = GridSearchCV(RF_clf,RFparameters, cv = 5, n_jobs=-1)\n",
    "RF_clf=RF_clf.fit(review_text_train[\"review\"], review_text_train_meta[\"rating\"])\n",
    "RF_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'gini',\n",
       " 'clf__min_samples_split': 2,\n",
       " 'tfidf__use_idf': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7535271483539975"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomforestclassifier with vect50\n",
    "RF_clf=Pipeline([\n",
    "                (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "RFparameters={\n",
    "    \"clf__criterion\":[\"gini\",\"entropy\"],\n",
    "    \"clf__min_samples_split\":[6,8,9,10,12]\n",
    "}\n",
    "RF_clf = GridSearchCV(RF_clf,RFparameters, cv = 5, n_jobs=-1)\n",
    "RF_clf=RF_clf.fit(review50, review_text_train_meta[\"rating\"])\n",
    "RF_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy', 'clf__min_samples_split': 9}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7399173435941285"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomforestclassifier with vect100\n",
    "RF_clf=Pipeline([\n",
    "                (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "RFparameters={\n",
    "    \"clf__criterion\":[\"gini\",\"entropy\"],\n",
    "    \"clf__min_samples_split\":[6,8,9,10,12,20]\n",
    "}\n",
    "RF_clf = GridSearchCV(RF_clf,RFparameters, cv = 5, n_jobs=-1)\n",
    "RF_clf=RF_clf.fit(review100, review_text_train_meta[\"rating\"])\n",
    "RF_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy', 'clf__min_samples_split': 20}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_clf = RandomForestClassifier(criterion=\"entropy\", min_samples_split=9) # vect50\n",
    "\n",
    "SVM_clf = SVM_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                (\"clf\", svm.SVC(kernel='linear', gamma=0.6, C=1.0))]) # countvect\n",
    "\n",
    "NB_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=False)),\n",
    "                (\"clf\", MultinomialNB(alpha=0.1, fit_prior=False))]) # countvect\n",
    "\n",
    "MLP_clf = Pipeline([('vect',CountVectorizer(stop_words=\"english\",decode_error='ignore')),\n",
    "                    (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                    ('clf',MLPClassifier(activation='relu', alpha=1e-05, \n",
    "                                         hidden_layer_sizes=(80,100,100), solver='lbfgs'))]) # countvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#stacking\n",
    "RF_clf = RandomForestClassifier(criterion=\"entropy\", min_samples_split=9) # vect50\n",
    "\n",
    "SVM_clf = SVM_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                (\"clf\", svm.SVC(kernel='linear', gamma=0.6, C=1.0))]) # countvect\n",
    "\n",
    "NB_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=False)),\n",
    "                (\"clf\", MultinomialNB(alpha=0.1, fit_prior=False))]) # countvect\n",
    "\n",
    "MLP_clf = Pipeline([('vect',CountVectorizer(stop_words=\"english\",decode_error='ignore')),\n",
    "                    (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                    ('clf',MLPClassifier(activation='relu', alpha=1e-05, \n",
    "                     hidden_layer_sizes=(80,100,100), solver='lbfgs'))]) # countvect\n",
    "\n",
    "\n",
    "other=svm.SVC(kernel='rbf', gamma=0.7, C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'o54U2VkQama8FI30qDkWvw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2b7755d2eab3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mSVM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSVM_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_text_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"review\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreview_text_train_meta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMLP_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_text_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"review\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreview_text_train_meta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0motherinfo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreview_text_train_meta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    144\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[0;32m    145\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mH:\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'o54U2VkQama8FI30qDkWvw'"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "NB=NB_clf.fit(review_text_train[\"review\"], review_text_train_meta[\"rating\"])\n",
    "RF=RF_clf.fit(review50,review_text_train_meta[\"rating\"])\n",
    "SVM=SVM_clf.fit(review_text_train[\"review\"],review_text_train_meta[\"rating\"])\n",
    "MLP=MLP_clf.fit(review_text_train[\"review\"],review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherinfo = review_text_train_meta[[\"vote_funny\", \"vote_cool\", \"vote_useful\"]]\n",
    "otherinfo_test = review_text_test_meta[[\"vote_funny\", \"vote_cool\", \"vote_useful\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.7, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other.fit(otherinfo,review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBresult=NB.predict(review_text_train[\"review\"])\n",
    "SVMresult=SVM.predict(review_text_train[\"review\"])\n",
    "RFresult=RF.predict(review50)\n",
    "MLPresult=MLP.predict(review_text_train[\"review\"])\n",
    "otherresult = other.predict(otherinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.DataFrame([NBresult, SVMresult,RFresult,MLPresult,otherresult]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=LogisticRegression()\n",
    "final.fit(finaldf,review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7013</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7018 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     5\n",
       "1     5\n",
       "2     1\n",
       "3     3\n",
       "4     5\n",
       "...  ..\n",
       "7013  5\n",
       "7014  5\n",
       "7015  3\n",
       "7016  5\n",
       "7017  5\n",
       "\n",
       "[7018 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the predicted results of test\n",
    "\n",
    "predictdf = pd.DataFrame([NB.predict(review_text_test[\"review\"]),\n",
    "                          SVM.predict(review_text_test[\"review\"]),\n",
    "                          RF.predict(review50_test),\n",
    "                          MLP.predict(review_text_test[\"review\"]),\n",
    "                          other.predict(otherinfo_test)]).T\n",
    "\n",
    "result_test=pd.DataFrame(final.predict(predictdf))\n",
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test.to_csv(\"predict_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639803334758443"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self check\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictdf = pd.DataFrame([NB.predict(review_text_train[\"review\"]),\n",
    "                          SVM.predict(review_text_train[\"review\"]),\n",
    "                          RF.predict(review50),\n",
    "                          MLP.predict(review_text_train[\"review\"]),\n",
    "                          other.predict(otherinfo)]).T\n",
    "\n",
    "result=final.predict(predictdf)\n",
    "acc = accuracy_score(review_text_train_meta[\"rating\"],result)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7018,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test=SVM.predict(review_text_test[\"review\"])\n",
    "result_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predict(result_test):\n",
    "    id = [i for i in range(1,7019)]\n",
    "    final_df = pd.DataFrame([id, result_test]).T\n",
    "    final_df = final_df.rename(columns={0:\"instance_id\", 1:\"rating\"})\n",
    "    return final_df\n",
    "print_predict(result_test).to_csv(\"SVMpredict.csv\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-cv stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def cross_validation(data, k):\n",
    "    tmp_df = df.sample(frac=1)\n",
    "    df_list = []\n",
    "    length = tmp_df.shape[0]//k\n",
    "    remain = tmp_df.shape[0]%k\n",
    "    last_index = copy.deepcopy(length)\n",
    "    i = 0\n",
    "    while(i<tmp_df.shape[0]):\n",
    "        if remain>0:\n",
    "            last_index += 1\n",
    "            remain -= 1\n",
    "        df_list.append(tmp_df.iloc[i:last_index])\n",
    "        i = last_index\n",
    "        last_index = i + length\n",
    "        \n",
    "    acc_list = []\n",
    "    for i in range(k):\n",
    "        tmp_list = copy.deepcopy(df_list)\n",
    "        test_set = tmp_list.pop(i)\n",
    "        train_set = pd.concat(tmp_list, axis = 0)\n",
    "        train_dict = train(train_set)\n",
    "        predict_df = predict(test_set, train_dict)\n",
    "        evaluate_dict = evaluate(predict_df)\n",
    "        acc_list.append(evaluate_dict[0])\n",
    "    return acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = review_text_train_meta[[\"rating\"]]\n",
    "df_meta = review_text_train_meta[[\"vote_funny\", \"vote_cool\", \"vote_useful\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x, y):\n",
    "    x1, remain_x1, y1, remain_y1 = train_test_split(x, y, test_size = 0.8, random_state = 42)\n",
    "    x2, remain_x2, y2, remain_y2 = train_test_split(remain_x1, remain_y1, test_size = 0.75, random_state = 42)\n",
    "    x3, remain_x3, y2, remain_y3 = train_test_split(remain_x2, remain_y2, test_size = 0.6666, random_state = 42)\n",
    "    x4, x5, y4, y5 = train_test_split(remain_x3, remain_y3, test_size = 0.5, random_state = 42)\n",
    "    x_list = [x1, x2, x3, x4, x5]\n",
    "    y_list = [y1, y2, y3, y4, y5]\n",
    "    return [x_list, y_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vect50, y_vect50 = split(review50, df_rating)\n",
    "x_review, y_review = split(review_text_train, df_rating)\n",
    "x_meta, y_meta = split(df_meta, df_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(clf, x1, x2, y1):\n",
    "    clf.fit(x1.y1)\n",
    "    return clf.predict(x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict use 4 out of 5 x,y\n",
    "final=Dataframe()\n",
    "for test in range(5):\n",
    "    test_meta=x_meta[test]\n",
    "    test_review=x_review[test]\n",
    "    test_vect50=x_vect50[test]\n",
    "    train_meta=Dataframe()\n",
    "    train_review=Dataframe()\n",
    "    train_vect50=Dataframe()\n",
    "    \n",
    "    for i in range(5):\n",
    "        if i!=test:\n",
    "            train_meta.join(x_meta[i])\n",
    "            train_vect50.join(x_vect50[i])\n",
    "            train_review.join(x_review[i])\n",
    "    \n",
    "    # fit the model\n",
    "    NB=NB_clf.fit(train_review[\"review\"], train_meta[\"rating\"])\n",
    "    RF=RF_clf.fit(train_vect50, train_meta[\"rating\"])\n",
    "    SVM=SVM_clf.fit(train_review[\"review\"], train_meta[\"rating\"])\n",
    "    MLP=MLP_clf.fit(train_review[\"review\"], train_meta[\"rating\"])\n",
    "    \n",
    "    otherinfo=test_meta[[\"vote_funny\", \"vote_cool\", \"vote_useful\"]]\n",
    "    NBresult=NB.predict(test_review[\"review\"])\n",
    "    SVMresult=SVM.predict(test_review[\"review\"])\n",
    "    RFresult=RF.predict(test_review[\"review\"])\n",
    "    MLPresult=MLP.predict(test_review[\"review\"])\n",
    "    otherresult = other.predict(otherinfo)\n",
    "\n",
    "    finaldf = Dataframe()\n",
    "    finaldf.join(NBresult)\n",
    "    finaldf.join(SVMresult)\n",
    "    finaldf.join(otherresult)\n",
    "    finaldf.join(MLPresult)\n",
    "    finaldf.join(RFresult)\n",
    "    final=pd.concat([final,finaldf], axis=0)\n",
    "\n",
    "final=LogisticRegression()\n",
    "final.fit(final,df[\"rating\"])\n",
    "\n",
    "#predict\n",
    "predictdf=Dataframe()\n",
    "#get the predicted results of test\n",
    "predictdf.join(NB.predict(predictreview))\n",
    "predictdf.join(SVM.predict(predictreview))\n",
    "predictdf.join(RF.predict(predictreview))\n",
    "predictdf.join(MLP.predict(predictreview))\n",
    "\n",
    "predictdf.join(other.predict(predictmeta.drop([\"rating\"], axis=1)))\n",
    "result=final.predict(predictdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
