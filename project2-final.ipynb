{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2020 Semester 1\n",
    "\n",
    "## Assignment 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):**    `Yanze Mao, Dong Cheng Ding\n",
    "\n",
    "**Student ID(s):**     `988142 952328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "review_text_test = pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_test.csv\")\n",
    "review_text_train = pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_train.csv\")\n",
    "review_text_test_meta = pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_meta_test.csv\")\n",
    "review_text_train_meta = pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_meta_train.csv\")\n",
    "review50=pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_train_doc2vec50.csv\",header=None)\n",
    "review100=pd.read_csv(\"COMP30027_2020_assignment2_datasets\\\\review_text_train_doc2vec100.csv\",header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB with countvectorizer\n",
    "\n",
    "NB_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer()),\n",
    "                (\"clf\", MultinomialNB())])\n",
    "NBparameters={\n",
    "     'tfidf__use_idf':(True,False),\n",
    "    'clf__alpha':[0,0.001,0.01,0.1,0.2],\n",
    "    'clf__fit_prior':[True,False]\n",
    "}\n",
    "NB_clf = GridSearchCV(NB_clf,NBparameters, cv = 5, n_jobs=-1)\n",
    "NB_clf=NB_clf.fit(review_text_train[\"review\"], review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__use_idf': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8413852073535699"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB with vect50,100,200\n",
    "\n",
    "NB_clf=Pipeline([\n",
    "                (\"clf\", GaussianNB())])\n",
    "NBparameters={\n",
    "    'clf__var_smoothing':[1e-9,1e-8]\n",
    "}\n",
    "NB_clf = GridSearchCV(NB_clf,NBparameters, cv = 5, n_jobs=-1)\n",
    "NB_clf=NB_clf.fit(review50, review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__var_smoothing': 1e-09}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6701938150206641"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84683882, 0.85518347, 0.84574279, 0.8376982 , 0.8492516 ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after adjustment of attributes, the best estimator with countervect:\n",
    "\n",
    "MLP_clf = Pipeline([('vect',CountVectorizer(stop_words=\"english\",decode_error='ignore')),\n",
    "                    (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                    ('clf',MLPClassifier(activation='relu', alpha=1e-05,\n",
    "       hidden_layer_sizes=(80,100,100), solver='lbfgs'))])\n",
    "\n",
    "\n",
    "scores2 = cross_validate(MLP_clf, review_text_train[\"review\"], review_text_train_meta[\"rating\"], cv = 5)\n",
    "scores2[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469429769356409"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75494212, 0.77075169, 0.76505166, 0.76679138, 0.76799715])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after adjustment of attributes, the best estimator with vect50,100,200:\n",
    "\n",
    "MLP_clf = Pipeline([\n",
    "                    ('clf',MLPClassifier(activation='relu', alpha=1e-05,\n",
    "       hidden_layer_sizes=(80,100,100), solver='lbfgs'))])\n",
    "\n",
    "\n",
    "scores2 = cross_validate(MLP_clf, review50, review_text_train_meta[\"rating\"], cv = 5)\n",
    "scores2[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76028495, 0.76237976, 0.7680798 , 0.76946374, 0.76853172])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after adjustment of attributes, the best estimator with vect50,100,200:\n",
    "\n",
    "MLP_clf = Pipeline([\n",
    "                    ('clf',MLPClassifier(solver='lbfgs'))])\n",
    "\n",
    "\n",
    "scores2 = cross_validate(MLP_clf, review100, review_text_train_meta[\"rating\"], cv = 5)\n",
    "scores2[\"test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with countervect\n",
    "SVM_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                (\"clf\", svm.SVC(kernel='linear', gamma=0.7, C=1.0))])\n",
    "\n",
    "SVMparameters={\n",
    "    \"clf__gamma\":[0.6,0.7,0.5,0.4],\n",
    "    \"clf__C\":[0.5,0.7,1.0,2.0]\n",
    "}\n",
    "SVMgs_clf = GridSearchCV(SVM_clf,SVMparameters, cv = 5, n_jobs=-1)\n",
    "SVMgs_clf=SVMgs_clf.fit(review_text_train[\"review\"], review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1.0, 'clf__gamma': 0.6}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMgs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMgs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with vect100\n",
    "SVM_clf=Pipeline([\n",
    "                (\"clf\", svm.SVC(kernel='linear', gamma=0.7, C=1.0))])\n",
    "\n",
    "SVMparameters={\n",
    "    \"clf__gamma\":[0.6,0.7,0.5,0.4],\n",
    "    \"clf__C\":[0.5,0.7,1.0,2.0]\n",
    "}\n",
    "SVMgs_clf = GridSearchCV(SVM_clf,SVMparameters, cv = 5, n_jobs=-1)\n",
    "SVMgs_clf=SVMgs_clf.fit(review100, review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8265640587145504"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMgs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with vect100\n",
    "SVM_clf=Pipeline([\n",
    "                (\"clf\", svm.SVC(kernel='linear', gamma=0.7, C=1.0))])\n",
    "\n",
    "SVMparameters={\n",
    "    \"clf__gamma\":[0.6,0.7,0.5,0.4],\n",
    "    \"clf__C\":[0.5,0.7,1.0,2.0]\n",
    "}\n",
    "SVMgs_clf = GridSearchCV(SVM_clf,SVMparameters, cv = 5, n_jobs=-1)\n",
    "SVMgs_clf=SVMgs_clf.fit(review50, review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8165170300698305"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMgs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.7, 'clf__gamma': 0.6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMgs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomforestclassifier with countervect\n",
    "RF_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "RFparameters={\n",
    "    \"tfidf__use_idf\":[True,False],\n",
    "    \"clf__n_estimators\":[100,300,500],\n",
    "    \"clf__criterion\":[\"gini\",\"entropy\"],\n",
    "    \"clf__max_depth\":[10,15,20,30],\n",
    "    \"clf__min_samples_split\":[2,4,6],\n",
    "}\n",
    "RF_clf = GridSearchCV(RF_clf,RFparameters, cv = 5, n_jobs=-1)\n",
    "RF_clf=RF_clf.fit(review_text_train[\"review\"], review_text_train_meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'gini',\n",
       " 'clf__max_depth': 30,\n",
       " 'clf__min_samples_split': 2,\n",
       " 'clf__n_estimators': 100,\n",
       " 'tfidf__use_idf': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6955251531993729"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7509975773122417"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomforestclassifier with countervect\n",
    "RF_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "RFparameters={\n",
    "    \"tfidf__use_idf\":[False],\n",
    "    \"clf__criterion\":[\"gini\",\"entropy\"],\n",
    "    \"clf__min_samples_split\":[2,4,6]\n",
    "}\n",
    "RF_clf = GridSearchCV(RF_clf,RFparameters, cv = 5, n_jobs=-1)\n",
    "RF_clf=RF_clf.fit(review_text_train[\"review\"], review_text_train_meta[\"rating\"])\n",
    "RF_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'gini',\n",
       " 'clf__min_samples_split': 2,\n",
       " 'tfidf__use_idf': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7535271483539975"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomforestclassifier with vect50\n",
    "RF_clf=Pipeline([\n",
    "                (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "RFparameters={\n",
    "    \"clf__criterion\":[\"gini\",\"entropy\"],\n",
    "    \"clf__min_samples_split\":[6,8,9,10,12]\n",
    "}\n",
    "RF_clf = GridSearchCV(RF_clf,RFparameters, cv = 5, n_jobs=-1)\n",
    "RF_clf=RF_clf.fit(review50, review_text_train_meta[\"rating\"])\n",
    "RF_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy', 'clf__min_samples_split': 9}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7399173435941285"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomforestclassifier with vect100\n",
    "RF_clf=Pipeline([\n",
    "                (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "RFparameters={\n",
    "    \"clf__criterion\":[\"gini\",\"entropy\"],\n",
    "    \"clf__min_samples_split\":[6,8,9,10,12,20]\n",
    "}\n",
    "RF_clf = GridSearchCV(RF_clf,RFparameters, cv = 5, n_jobs=-1)\n",
    "RF_clf=RF_clf.fit(review100, review_text_train_meta[\"rating\"])\n",
    "RF_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy', 'clf__min_samples_split': 20}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_clf = RandomForestClassifier(criterion=\"entropy\", min_samples_split=9) # vect50\n",
    "\n",
    "SVM_clf = SVM_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                (\"clf\", svm.SVC(kernel='linear', gamma=0.6, C=1.0))]) # countvect\n",
    "\n",
    "NB_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                (\"tfidf\",TfidfTransformer(use_idf=False)),\n",
    "                (\"clf\", MultinomialNB(alpha=0.1, fit_prior=False))]) # countvect\n",
    "\n",
    "MLP_clf = Pipeline([('vect',CountVectorizer(stop_words=\"english\",decode_error='ignore')),\n",
    "                    (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                    ('clf',MLPClassifier(activation='relu', alpha=1e-05, \n",
    "                                         hidden_layer_sizes=(80,100,100), solver='lbfgs'))]) # countvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB=NB_clf.fit(review, meta[\"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#stacking\n",
    "def stacking(review,vec50,meta,predictreview,predictmeta):\n",
    "    #input: review - raw train text\n",
    "    #input: meta - include rating\n",
    "    #input: vec50 for Rndom forest\n",
    "    #find train dataset's prediction\n",
    "\n",
    "    RF_clf = RandomForestClassifier(criterion=\"entropy\", min_samples_split=9) # vect50\n",
    "\n",
    "    SVM_clf = SVM_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                    (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                    (\"clf\", svm.SVC(kernel='linear', gamma=0.6, C=1.0))]) # countvect\n",
    "\n",
    "    NB_clf=Pipeline([(\"vect\", CountVectorizer(stop_words=\"english\", decode_error=\"ignore\")), \n",
    "                    (\"tfidf\",TfidfTransformer(use_idf=False)),\n",
    "                    (\"clf\", MultinomialNB(alpha=0.1, fit_prior=False))]) # countvect\n",
    "\n",
    "    MLP_clf = Pipeline([('vect',CountVectorizer(stop_words=\"english\",decode_error='ignore')),\n",
    "                        (\"tfidf\",TfidfTransformer(use_idf=True)),\n",
    "                        ('clf',MLPClassifier(activation='relu', alpha=1e-05, \n",
    "                         hidden_layer_sizes=(80,100,100), solver='lbfgs'))]) # countvect\n",
    "    print(review, meta[\"rating\"])\n",
    "    #get the predicted results of train\n",
    "    NB=NB_clf.fit(review, meta[\"rating\"])\n",
    "    RF=RF_clf.fit(vec50,meta[\"rating\"])\n",
    "    SVM=SVM_clf.fit(review,meta[\"rating\"])\n",
    "    MLP=MLP_clf.fit(review,meta[\"rating\"])\n",
    "    \n",
    "\n",
    "    otherinfo = meta.drop(['rating'], axis=1)\n",
    "    \n",
    "    other=svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n",
    "    \n",
    "    other.fit(otherinfo,df[\"rating\"])\n",
    "\n",
    "    NBresult=NB.predict(reivew, meta[\"rating\"])\n",
    "    SVMresult=SVM.predict(reivew, meta[\"rating\"])\n",
    "    RFresult=RF.predict(reivew, meta[\"rating\"])\n",
    "    MLPresult=MLP.predict(reivew, meta[\"rating\"])\n",
    "    finaldf = Dataframe()\n",
    "    finaldf.join(NBresult)\n",
    "    finaldf.join(SVMresult)\n",
    "    finaldf.join(otherresult)\n",
    "    finaldf.join(MLPresult)\n",
    "    finaldf.join(RFresult)\n",
    "    \n",
    "    final=LogisticRegression()\n",
    "    final.fit(finaldf,df[\"rating\"])\n",
    "    \n",
    "    #predict\n",
    "    predictdf=Dataframe()\n",
    "    #get the predicted results of test\n",
    "    predictdf.join(NB.predict(predictreview))\n",
    "    predictdf.join(SVM.predict(predictreview))\n",
    "    predictdf.join(RF.predict(predictreview))\n",
    "    predictdf.join(MLP.predict(predictreview))\n",
    "\n",
    "    predictdf.join(other.predict(predictmeta.drop([\"rating\"], axis=1)))\n",
    "    result=final.predict(predictdf)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review\n",
      "0      dear longman & eagle.......you've left me no c...\n",
      "1      Delish. The hubby and I wanted to do brunch on...\n",
      "2      yep, I've giving Yolk 5 stars. It's just reall...\n",
      "3      Meat, meat, meat. It's meat-tastic. So much me...\n",
      "4      I caught up with the law school girls on a Sat...\n",
      "5      Man I love Doug and his delicious sausages... ...\n",
      "6      My boyfriend and I have started going to Nana'...\n",
      "7      Overall, the food wasn't memorable. On the tas...\n",
      "8      The Bad Apple is truly kick-ass. There are so ...\n",
      "9      Rewind back to 2007: This place is my favorite...\n",
      "10     It's really hard to say one restaurant in Chic...\n",
      "11     If you asked me to review Icosium Kafe two wee...\n",
      "12     This place was fantastic! Our waitress was ver...\n",
      "13     I eat breakfast here at least once a week, alt...\n",
      "14     I'm not a big Deep Dish Pizza guy, but this pl...\n",
      "15     Finally, al la carte card #1 used! Had the ple...\n",
      "16     I loved Chicago Q! Highlights: -Delicious hous...\n",
      "17     I would try to defend this GREAT pizzeria from...\n",
      "18     Cheap food that's always great in a comfortabl...\n",
      "19     I am not a deep dish pizza kinda girl. I love ...\n",
      "20     The Good: -The absolute BEST deep dish pizza I...\n",
      "21     A great local breakfast place. Be warned thoug...\n",
      "22     our first visit to Zed was more than fantastic...\n",
      "23     I love this place and can't get enough of it. ...\n",
      "24     Family and I went here for mother's day... My ...\n",
      "25     This place is truly as good as it gets. Don't ...\n",
      "26     Calo is solid. My first experience here was at...\n",
      "27     I think Pequod's has decent pizza but I don't ...\n",
      "28     So, I was really excited to check this place o...\n",
      "29     over two hours wait for this place? a place th...\n",
      "...                                                  ...\n",
      "28038  Sorry to say this place was just not for me. T...\n",
      "28039  Darkly moody, brooding, classy, vintage. This ...\n",
      "28040  We don't eat a lot of take out, but we happen ...\n",
      "28041  I was so excited to finally go to the Green Mi...\n",
      "28042  Best...pizza...ever. I could not possibly say ...\n",
      "28043  My friend and I both loved the food here. We h...\n",
      "28044  Went for weekend brunch. The food was still gr...\n",
      "28045  Coast always pleases me, we were hungry and it...\n",
      "28046  If you love deep dish and loads of toppings th...\n",
      "28047  Thoroughly impressed with Graham Elliot--an ex...\n",
      "28048  We got here a little before it closed so we go...\n",
      "28049  Delicious food. Fantastic service. Taste every...\n",
      "28050  Great food, good service, EXCELLENT prices! Tr...\n",
      "28051  Wonderful experience. Food was inventive and f...\n",
      "28052  This place is a wee bit overrated. I think Yup...\n",
      "28053  The sandwhiches are great, but if you have twe...\n",
      "28054  Brought 3 guests from out of town who wanted t...\n",
      "28055  I love this place, JB I think you couldn't see...\n",
      "28056  Bridgeport has needed a spot like this for yea...\n",
      "28057  This is a review of Geno's East frozen pizza- ...\n",
      "28058  This places pizza is awesome, the beer is even...\n",
      "28059  The Peking duck here is life-changing. By life...\n",
      "28060  Some yelpers and I checked this place out prio...\n",
      "28061               Service is so so, but good food!\\r\\n\n",
      "28062  I don't understand what all the fuss is about....\n",
      "28063  This afternoon I went to Yolk with my college ...\n",
      "28064  Place has lots of side dishes. But that's abou...\n",
      "28065  I am a huge fan of Brazillian steakhouses I've...\n",
      "28066                                  Great Brunch.\\r\\n\n",
      "28067  I love The Chicago Diner. I first came here ab...\n",
      "\n",
      "[28068 rows x 1 columns] 0        1\n",
      "1        5\n",
      "2        5\n",
      "3        3\n",
      "4        3\n",
      "5        5\n",
      "6        5\n",
      "7        3\n",
      "8        5\n",
      "9        3\n",
      "10       5\n",
      "11       1\n",
      "12       5\n",
      "13       3\n",
      "14       3\n",
      "15       5\n",
      "16       5\n",
      "17       5\n",
      "18       5\n",
      "19       5\n",
      "20       5\n",
      "21       5\n",
      "22       5\n",
      "23       5\n",
      "24       5\n",
      "25       5\n",
      "26       5\n",
      "27       3\n",
      "28       3\n",
      "29       5\n",
      "        ..\n",
      "28038    3\n",
      "28039    5\n",
      "28040    5\n",
      "28041    1\n",
      "28042    5\n",
      "28043    5\n",
      "28044    3\n",
      "28045    3\n",
      "28046    5\n",
      "28047    5\n",
      "28048    3\n",
      "28049    5\n",
      "28050    5\n",
      "28051    5\n",
      "28052    1\n",
      "28053    5\n",
      "28054    5\n",
      "28055    5\n",
      "28056    5\n",
      "28057    1\n",
      "28058    5\n",
      "28059    5\n",
      "28060    3\n",
      "28061    3\n",
      "28062    3\n",
      "28063    1\n",
      "28064    1\n",
      "28065    5\n",
      "28066    5\n",
      "28067    5\n",
      "Name: rating, Length: 28068, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 28068]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4467fbd1592f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_text_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview_text_train_meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview_text_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreview_text_train_meta\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-2d17bc7cf84f>\u001b[0m in \u001b[0;36mstacking\u001b[1;34m(review, vec50, meta, predictreview, predictmeta)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#get the predicted results of train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mNB\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNB_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mRF\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRF_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mSVM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSVM_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \"\"\"\n\u001b[1;32m--> 585\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 28068]"
     ]
    }
   ],
   "source": [
    "\n",
    "print(stacking(review_text_train, review50, review_text_train_meta, review_text_train,review_text_train_meta ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
